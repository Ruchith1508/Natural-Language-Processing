{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fde9eb-7ba0-4a96-b08a-95f96beb779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0eca42-9591-47f8-863b-5bb8e929c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in /Users/ruchithreddyparnem/opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867971f1-41f4-45ad-b63e-c11ca7947a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Dataset\n",
    "df = pd.read_csv('movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e3064b-ce0e-4772-a4b5-69f8f9a50ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "709639f3-e24a-422d-a715-681c4f3ebd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d5441b-50d5-4fa0-92c7-94e5f72c3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dcbebaa-8c4a-426e-bfcc-7bf5a5347229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stop words\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "STOP_WORDS = set(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a1eb1c-45fe-438a-9f32-517fcb4a2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data for testing and traning\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = df_shuffled.iloc[:1000].copy()\n",
    "remaining_df = df_shuffled.iloc[1000:].copy()\n",
    "test_pool_class_0 = remaining_df[remaining_df['label'] == 0]\n",
    "test_pool_class_1 = remaining_df[remaining_df['label'] == 1]\n",
    "test_class_0 = test_pool_class_0.sample(n=100, random_state=42)\n",
    "test_class_1 = test_pool_class_1.sample(n=100, random_state=42)\n",
    "test_df = pd.concat([test_class_0, test_class_1]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20afcee9-8d08-4dff-bad8-93f1e682300f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The central theme in this movie seems to be co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ending made my heart jump up into my throa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only the chosen ones will appreciate the quali...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a really funny film, especially the se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Together with the even more underrated , The S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I bought this DVD after seeing it highly ranke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>This is a known fact, Mr. Seagal cannot smile,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>I must have been in a good mood to give this s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Sorry Randy. I love your comedy but in this ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    The central theme in this movie seems to be co...      0\n",
       "1    An excellent example of \"cowboy noir\", as it's...      1\n",
       "2    The ending made my heart jump up into my throa...      0\n",
       "3    Only the chosen ones will appreciate the quali...      1\n",
       "4    This is a really funny film, especially the se...      1\n",
       "..                                                 ...    ...\n",
       "995  Together with the even more underrated , The S...      1\n",
       "996  I bought this DVD after seeing it highly ranke...      0\n",
       "997  This is a known fact, Mr. Seagal cannot smile,...      0\n",
       "998  I must have been in a good mood to give this s...      0\n",
       "999  Sorry Randy. I love your comedy but in this ca...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# traing data\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66629b5e-5823-4188-b186-da2e7b45e6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd have to agree with the previous reviewer: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been a huge Lynn Peterson fan ever sinc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am one of the biggest fans of silent comedia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlantis was much better than I had anticipate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seth McFarlane is a true genius. He has crafte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>There is a lot of crap coming out of Hollywood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>This is one for the Golden Turkey book. It's a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>As I write this user-comment, Tim Burton's int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>LE GRAND VOYAGE is a gentle miracle of a film,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>I just wanted to say that I am watching Nation...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    I'd have to agree with the previous reviewer: ...      0\n",
       "1    I have been a huge Lynn Peterson fan ever sinc...      0\n",
       "2    I am one of the biggest fans of silent comedia...      0\n",
       "3    Atlantis was much better than I had anticipate...      1\n",
       "4    Seth McFarlane is a true genius. He has crafte...      1\n",
       "..                                                 ...    ...\n",
       "195  There is a lot of crap coming out of Hollywood...      1\n",
       "196  This is one for the Golden Turkey book. It's a...      0\n",
       "197  As I write this user-comment, Tim Burton's int...      0\n",
       "198  LE GRAND VOYAGE is a gentle miracle of a film,...      1\n",
       "199  I just wanted to say that I am watching Nation...      1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a96861-46c4-4850-a275-57be7a5feb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20111</th>\n",
       "      <td>When recounting these events that took place s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>No mention if Ann Rivers Siddons adapted the m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31656</th>\n",
       "      <td>This is one strange hacked together film, you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9386</th>\n",
       "      <td>No redeeming features, this film is rubbish. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Advertised by channel seven in Australia as th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>I'd have to agree with the previous reviewer: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11153</th>\n",
       "      <td>Even my five year old was bored.&lt;br /&gt;&lt;br /&gt;Ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>Wow. Not because of the 3-D imagery, which at ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>This movie was o.k. but it could have been muc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>There really wasn't much of a story in this fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "20111  When recounting these events that took place s...      0\n",
       "1814   No mention if Ann Rivers Siddons adapted the m...      0\n",
       "31656  This is one strange hacked together film, you ...      0\n",
       "9386   No redeeming features, this film is rubbish. I...      0\n",
       "18452  Advertised by channel seven in Australia as th...      0\n",
       "...                                                  ...    ...\n",
       "5396   I'd have to agree with the previous reviewer: ...      0\n",
       "11153  Even my five year old was bored.<br /><br />Ve...      0\n",
       "4476   Wow. Not because of the 3-D imagery, which at ...      0\n",
       "30287  This movie was o.k. but it could have been muc...      0\n",
       "6153   There really wasn't much of a story in this fi...      0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data of negative class\n",
    "test_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4c059a-eaca-443d-a136-0a42fd1e9b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28101</th>\n",
       "      <td>This probably ranks in my Top-5 list of the fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>Zachary Scott does what he does best, i.e., pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33940</th>\n",
       "      <td>I just wanted to say that I am watching Nation...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20581</th>\n",
       "      <td>This movie is the Latino Godfather. An unlikel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36006</th>\n",
       "      <td>I'll be brief: I normally hate films like this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20625</th>\n",
       "      <td>A grumpy old baronet, happily unmarried, decid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23568</th>\n",
       "      <td>Back in 74 Eric Monte made the classic T.V sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22148</th>\n",
       "      <td>Nicely and intelligently played by the two you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>Bwana Devil is reputedly the first major studi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10056</th>\n",
       "      <td>I very much enjoyed \"The Revolution Will Not B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "28101  This probably ranks in my Top-5 list of the fu...      1\n",
       "7086   Zachary Scott does what he does best, i.e., pl...      1\n",
       "33940  I just wanted to say that I am watching Nation...      1\n",
       "20581  This movie is the Latino Godfather. An unlikel...      1\n",
       "36006  I'll be brief: I normally hate films like this...      1\n",
       "...                                                  ...    ...\n",
       "20625  A grumpy old baronet, happily unmarried, decid...      1\n",
       "23568  Back in 74 Eric Monte made the classic T.V sho...      1\n",
       "22148  Nicely and intelligently played by the two you...      1\n",
       "3145   Bwana Devil is reputedly the first major studi...      1\n",
       "10056  I very much enjoyed \"The Revolution Will Not B...      1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data of positive class\n",
    "test_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bb81e6-39e7-4426-8dfd-503674e4037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: lemmatisation, removing stop words, handling negation, removing symbols.\n",
    "def preprocess_text(text, lemmatize_words=False, remove_stop_words=False, handle_logical_negation=False):\n",
    "    text = re.sub(r'<s>|</s>|<br>|<br/>', '. ', text)\n",
    "    tokens = text.split()\n",
    "    processed_tokens = []\n",
    "    \n",
    "    if handle_logical_negation:\n",
    "        negation_words = ['not', \"n't\", 'no']\n",
    "        negate_next = False\n",
    "        for token in tokens:\n",
    "            if negate_next:\n",
    "                processed_tokens.append(f\"{token}_NEG\")\n",
    "                negate_next = False\n",
    "            elif token.lower() in negation_words:\n",
    "                processed_tokens.append(token)\n",
    "                negate_next = True\n",
    "            else:\n",
    "                processed_tokens.append(token)\n",
    "        tokens = processed_tokens\n",
    "        processed_tokens = []\n",
    "    if remove_stop_words:\n",
    "        for token in tokens:\n",
    "            if token.lower() not in STOP_WORDS:\n",
    "                processed_tokens.append(token)\n",
    "        tokens = processed_tokens\n",
    "        processed_tokens = []\n",
    "    \n",
    "    processed_tokens = tokens\n",
    "    \n",
    "    return \" \".join(processed_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e12751e-cfb9-4849-997c-3c6d5031f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_simple(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(preprocess_text_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c61312-a2f4-4742-86be-c7fc150a8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developing Naive bayes\n",
    "class NaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_priors = {}\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.total_words_per_class = defaultdict(int)\n",
    "        self.vocabulary = set()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        num_reviews = len(y_train)\n",
    "        \n",
    "        for i, text in enumerate(X_train):\n",
    "            label = y_train.iloc[i]\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.total_words_per_class[label] += 1\n",
    "                self.vocabulary.add(word)\n",
    "        \n",
    "        # Calculate log prior probabilities\n",
    "        self.class_priors[0] = math.log(y_train.value_counts()[0] / num_reviews)\n",
    "        self.class_priors[1] = math.log(y_train.value_counts()[1] / num_reviews)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        \n",
    "        for text in X_test:\n",
    "            scores = {0: self.class_priors[0], 1: self.class_priors[1]}\n",
    "            words = text.split()\n",
    "            \n",
    "            for label in [0, 1]:\n",
    "                total_words = self.total_words_per_class[label]\n",
    "                for word in words:\n",
    "                    # Apply Laplace smoothing\n",
    "                    word_count = self.word_counts[label][word] + self.alpha\n",
    "                    total_count = total_words + self.alpha * vocab_size\n",
    "                    likelihood = word_count / total_count\n",
    "                    if likelihood > 0: # Avoid log(0)\n",
    "                        scores[label] += math.log(likelihood)\n",
    "            \n",
    "            if scores[0] > scores[1]:\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                predictions.append(1)\n",
    "                \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc686658-21e9-4c34-8424-581d7a6ed727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if pred == 1 and true == 1:\n",
    "            true_pos += 1\n",
    "        elif pred == 0 and true == 0:\n",
    "            true_neg += 1\n",
    "        elif pred == 1 and true == 0:\n",
    "            false_pos += 1\n",
    "        elif pred == 0 and true == 1:\n",
    "            false_neg += 1\n",
    "            \n",
    "    # Precision, Recall, F1 for each class\n",
    "    precision_0 = true_neg / (true_neg + false_neg) if (true_neg + false_neg) > 0 else 0\n",
    "    recall_0 = true_neg / (true_neg + false_pos) if (true_neg + false_pos) > 0 else 0\n",
    "    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0\n",
    "\n",
    "    precision_1 = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall_1 = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0\n",
    "    \n",
    "    return [[true_neg, false_pos], [false_neg, true_pos]], [precision_0, precision_1], [recall_0, recall_1], [f1_0, f1_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386dc6ad-a3f7-43d5-84eb-c5dca3658542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews in training set: 1000\n",
      "Number of positive reviews: 494\n",
      "Number of negative reviews: 506\n",
      "\n",
      "Prior Probability of Positive Class: 0.4940\n",
      "Prior Probability of Negative Class: 0.5060\n"
     ]
    }
   ],
   "source": [
    "# Calculating Prior Probabilities for Each Class\n",
    "class_counts = train_df['label'].value_counts()\n",
    "total_reviews = len(train_df)\n",
    "\n",
    "prior_positive = class_counts[1] / total_reviews\n",
    "prior_negative = class_counts[0] / total_reviews\n",
    "\n",
    "print(f\"Total reviews in training set: {total_reviews}\")\n",
    "print(f\"Number of positive reviews: {class_counts[1]}\")\n",
    "print(f\"Number of negative reviews: {class_counts[0]}\")\n",
    "print(f\"\\nPrior Probability of Positive Class: {prior_positive:.4f}\")\n",
    "print(f\"Prior Probability of Negative Class: {prior_negative:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23cc7199-181e-4e20-9384-a67a0d0b5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of 'great' in Positive Class: 0.00206769\n",
      "Likelihood of 'great' in Negative Class: 0.00088692\n"
     ]
    }
   ],
   "source": [
    "# Calculating Likelihood Values of Each Word Given Each Class\n",
    "# Example: calculate the likelihood of the word 'great'\n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(preprocess_text_simple)\n",
    "\n",
    "word_counts_by_class = defaultdict(lambda: defaultdict(int))\n",
    "total_words_by_class = defaultdict(int)\n",
    "vocabulary = set()\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    label = row['label']\n",
    "    words = row['text_cleaned'].split()\n",
    "    for word in words:\n",
    "        word_counts_by_class[label][word] += 1\n",
    "        total_words_by_class[label] += 1\n",
    "        vocabulary.add(word)\n",
    "\n",
    "word_to_check = 'great'\n",
    "positive_word_count = word_counts_by_class[1][word_to_check]\n",
    "negative_word_count = word_counts_by_class[0][word_to_check]\n",
    "total_positive_words = total_words_by_class[1]\n",
    "total_negative_words = total_words_by_class[0]\n",
    "\n",
    "likelihood_positive = positive_word_count / total_positive_words\n",
    "likelihood_negative = negative_word_count / total_negative_words\n",
    "\n",
    "print(f\"Likelihood of '{word_to_check}' in Positive Class: {likelihood_positive:.8f}\")\n",
    "print(f\"Likelihood of '{word_to_check}' in Negative Class: {likelihood_negative:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cb4bb91-91a5-4d9b-9fb3-cf20b70278a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Posterior Score for Positive Class: -42.2946\n",
      "Log Posterior Score for Negative Class: -43.3638\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Posterior Probability using Logarithmic Representation\n",
    "num_reviews = len(train_df)\n",
    "log_prior_positive = math.log(train_df['label'].value_counts()[1] / num_reviews)\n",
    "log_prior_negative = math.log(train_df['label'].value_counts()[0] / num_reviews)\n",
    "\n",
    "# Example Review\n",
    "example_review = \"This movie was great and I loved it.\"\n",
    "processed_review = preprocess_text_simple(example_review)\n",
    "\n",
    "log_posterior_positive = log_prior_positive\n",
    "log_posterior_negative = log_prior_negative\n",
    "\n",
    "for word in processed_review.split():\n",
    "    likelihood_positive = (word_counts_by_class[1][word] + 1) / (total_words_by_class[1] + len(vocabulary))\n",
    "    likelihood_negative = (word_counts_by_class[0][word] + 1) / (total_words_by_class[0] + len(vocabulary))\n",
    "\n",
    "    log_posterior_positive += math.log(likelihood_positive)\n",
    "    log_posterior_negative += math.log(likelihood_negative)\n",
    "\n",
    "print(f\"Log Posterior Score for Positive Class: {log_posterior_positive:.4f}\")\n",
    "print(f\"Log Posterior Score for Negative Class: {log_posterior_negative:.4f}\")\n",
    "\n",
    "predicted_class = 1 if log_posterior_positive > log_posterior_negative else 0\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e23adeb-7eeb-4831-aa63-7a91c0750218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of 'terrible' in positive class with Laplace smoothing (alpha=1): 0.0096\n"
     ]
    }
   ],
   "source": [
    "# using laplace smoothing\n",
    "class DummyNaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.total_words_per_class = defaultdict(int)\n",
    "        self.vocabulary = {'great', 'movie', 'terrible', 'plot'} # Example vocabulary\n",
    "\n",
    "    def calculate_likelihood(self, word, label):\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        \n",
    "        # Word and total counts with Laplace smoothing (alpha=1)\n",
    "        word_count = self.word_counts[label][word] + self.alpha\n",
    "        total_count = self.total_words_per_class[label] + self.alpha * vocab_size\n",
    "        \n",
    "        likelihood = word_count / total_count\n",
    "        return likelihood\n",
    "\n",
    "model = DummyNaiveBayes()\n",
    "model.word_counts[1]['great'] = 10  # 'great' appears 10 times in the positive class\n",
    "model.total_words_per_class[1] = 100 # Total words in the positive class\n",
    "\n",
    "word_to_check = 'terrible'\n",
    "\n",
    "# Likelihood without smoothing would be 0 for this unseen word\n",
    "# But with Laplace smoothing, the likelihood is non-zero\n",
    "likelihood_with_smoothing = model.calculate_likelihood(word_to_check, 1)\n",
    "\n",
    "print(f\"Likelihood of '{word_to_check}' in positive class with Laplace smoothing (alpha=1): {likelihood_with_smoothing:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "896d61f7-1721-4058-bd74-d9c8b592a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in the training vocabulary is: 17715\n",
      "The word 'fantastic' is in the training vocabulary: True\n",
      "The word 'stellar' is in the training vocabulary: True\n",
      "\n",
      "The unknown words in the test review are: []\n",
      "\n",
      "During prediction, words not in the training vocabulary are simply ignored by the model.\n"
     ]
    }
   ],
   "source": [
    "# Removing Unknown Words\n",
    "training_vocabulary = set()\n",
    "for text in train_df['text_cleaned']:\n",
    "    for word in text.split():\n",
    "        training_vocabulary.add(word)\n",
    "\n",
    "test_review_with_unknown = \"The movie was fantastic, absolutely stellar!\"\n",
    "processed_test_review = preprocess_text_simple(test_review_with_unknown)\n",
    "\n",
    "unknown_words = [word for word in processed_test_review.split() if word not in training_vocabulary]\n",
    "\n",
    "print(f\"The number of unique words in the training vocabulary is: {len(training_vocabulary)}\")\n",
    "print(f\"The word 'fantastic' is in the training vocabulary: {'fantastic' in training_vocabulary}\")\n",
    "print(f\"The word 'stellar' is in the training vocabulary: {'stellar' in training_vocabulary}\")\n",
    "print(f\"\\nThe unknown words in the test review are: {unknown_words}\")\n",
    "print(\"\\nDuring prediction, words not in the training vocabulary are simply ignored by the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca58499-bd14-4357-8f81-a995c07e1e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predicted Labels:\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "\n",
      "First 10 Actual Labels:\n",
      "[0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Performing Sentiment Analysis on the Test Data\n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=True, handle_logical_negation=True))\n",
    "test_df.loc[:, 'text_cleaned'] = test_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=True, handle_logical_negation=True))\n",
    "\n",
    "classifier = NaiveBayes(alpha=1.0)\n",
    "classifier.fit(train_df['text_cleaned'], train_df['label'])\n",
    "\n",
    "y_pred = classifier.predict(test_df['text_cleaned'])\n",
    "\n",
    "print(\"First 10 Predicted Labels:\")\n",
    "print(y_pred[:10])\n",
    "\n",
    "print(\"\\nFirst 10 Actual Labels:\")\n",
    "print(test_df['label'].iloc[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "990ab057-ed3c-4d99-b516-d38e5ac64b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[89, 11], [39, 61]]\n",
      "\n",
      "Precision per Class:\n",
      "Negative (Class 0): 0.6953\n",
      "Positive (Class 1): 0.8472\n",
      "\n",
      "Recall per Class:\n",
      "Negative (Class 0): 0.8900\n",
      "Positive (Class 1): 0.6100\n",
      "\n",
      "F-1 Score per Class:\n",
      "Negative (Class 0): 0.7807\n",
      "Positive (Class 1): 0.7093\n"
     ]
    }
   ],
   "source": [
    "# Calculating Confusion Matrix, Precision, Recall, and F1-Score\n",
    "classifier = NaiveBayes(alpha=1.0)\n",
    "classifier.fit(train_df['text_cleaned'], train_df['label'])\n",
    "\n",
    "y_pred = classifier.predict(test_df['text_cleaned'])\n",
    "y_test = test_df['label']\n",
    "\n",
    "conf_matrix, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nPrecision per Class:\")\n",
    "print(f\"Negative (Class 0): {precision[0]:.4f}\")\n",
    "print(f\"Positive (Class 1): {precision[1]:.4f}\")\n",
    "\n",
    "print(\"\\nRecall per Class:\")\n",
    "print(f\"Negative (Class 0): {recall[0]:.4f}\")\n",
    "print(f\"Positive (Class 1): {recall[1]:.4f}\")\n",
    "\n",
    "print(\"\\nF-1 Score per Class:\")\n",
    "print(f\"Negative (Class 0): {f1[0]:.4f}\")\n",
    "print(f\"Positive (Class 1): {f1[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4709466-4729-4d34-9344-304d8b45eca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scenario 1: No Preprocessing ---\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89, 11], [38, 62]]\n",
      "\n",
      "Metrics per Class:\n",
      "Negative (Class 0) - Precision: 0.7008, Recall: 0.8900, F1: 0.7841\n",
      "Positive (Class 1) - Precision: 0.8493, Recall: 0.6200, F1: 0.7168\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix, Precision, Reacll, F1 score without preprocessing \n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=False, remove_stop_words=False, handle_logical_negation=False))\n",
    "test_df.loc[:, 'text_cleaned'] = test_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=False, remove_stop_words=False, handle_logical_negation=False))\n",
    "\n",
    "X_train = train_df['text_cleaned']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text_cleaned']\n",
    "y_test = test_df['label']\n",
    "\n",
    "classifier = NaiveBayes(alpha=1.0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "conf_matrix, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Scenario 1: No Preprocessing ---\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nMetrics per Class:\")\n",
    "print(f\"Negative (Class 0) - Precision: {precision[0]:.4f}, Recall: {recall[0]:.4f}, F1: {f1[0]:.4f}\")\n",
    "print(f\"Positive (Class 1) - Precision: {precision[1]:.4f}, Recall: {recall[1]:.4f}, F1: {f1[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0db19b3e-5382-4bc8-9ba9-b6cee82a598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scenario 2: With Lemmatization Only ---\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89, 11], [38, 62]]\n",
      "\n",
      "Metrics per Class:\n",
      "Negative (Class 0) - Precision: 0.7008, Recall: 0.8900, F1: 0.7841\n",
      "Positive (Class 1) - Precision: 0.8493, Recall: 0.6200, F1: 0.7168\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix, Precision, Reacll, F1 score with lemmatisation only\n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=False, handle_logical_negation=False))\n",
    "test_df.loc[:, 'text_cleaned'] = test_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=False, handle_logical_negation=False))\n",
    "\n",
    "X_train = train_df['text_cleaned']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text_cleaned']\n",
    "y_test = test_df['label']\n",
    "\n",
    "classifier = NaiveBayes(alpha=1.0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "conf_matrix, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Scenario 2: With Lemmatization Only ---\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nMetrics per Class:\")\n",
    "print(f\"Negative (Class 0) - Precision: {precision[0]:.4f}, Recall: {recall[0]:.4f}, F1: {f1[0]:.4f}\")\n",
    "print(f\"Positive (Class 1) - Precision: {precision[1]:.4f}, Recall: {recall[1]:.4f}, F1: {f1[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5de9ee22-3e32-47ff-95c8-c647e6aae0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scenario 3: With Lemmatization and Removal of Stop Words ---\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90, 10], [38, 62]]\n",
      "\n",
      "Metrics per Class:\n",
      "Negative (Class 0) - Precision: 0.7031, Recall: 0.9000, F1: 0.7895\n",
      "Positive (Class 1) - Precision: 0.8611, Recall: 0.6200, F1: 0.7209\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix, Precision, Reacll, F1 score with lemmatisation and removal of stop words \n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=True, handle_logical_negation=False))\n",
    "test_df.loc[:, 'text_cleaned'] = test_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=True, handle_logical_negation=False))\n",
    "\n",
    "# Extract data and labels\n",
    "X_train = train_df['text_cleaned']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text_cleaned']\n",
    "y_test = test_df['label']\n",
    "\n",
    "classifier = NaiveBayes(alpha=1.0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "conf_matrix, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Scenario 3: With Lemmatization and Removal of Stop Words ---\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nMetrics per Class:\")\n",
    "print(f\"Negative (Class 0) - Precision: {precision[0]:.4f}, Recall: {recall[0]:.4f}, F1: {f1[0]:.4f}\")\n",
    "print(f\"Positive (Class 1) - Precision: {precision[1]:.4f}, Recall: {recall[1]:.4f}, F1: {f1[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aefea594-2ffc-4307-b67c-2712531d2061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scenario 4: All Preprocessing ---\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89, 11], [39, 61]]\n",
      "\n",
      "Metrics per Class:\n",
      "Negative (Class 0) - Precision: 0.6953, Recall: 0.8900, F1: 0.7807\n",
      "Positive (Class 1) - Precision: 0.8472, Recall: 0.6100, F1: 0.7093\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix, Precision, Reacll, F1 score with lemmatisation, removal of stop words and handling negation \n",
    "train_df.loc[:, 'text_cleaned'] = train_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=True, handle_logical_negation=True))\n",
    "test_df.loc[:, 'text_cleaned'] = test_df['text'].apply(\n",
    "    lambda x: preprocess_text(x, lemmatize_words=True, remove_stop_words=True, handle_logical_negation=True))\n",
    "\n",
    "X_train = train_df['text_cleaned']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text_cleaned']\n",
    "y_test = test_df['label']\n",
    "\n",
    "classifier = NaiveBayes(alpha=1.0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "conf_matrix, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "# Report results\n",
    "print(\"\\n--- Scenario 4: All Preprocessing ---\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nMetrics per Class:\")\n",
    "print(f\"Negative (Class 0) - Precision: {precision[0]:.4f}, Recall: {recall[0]:.4f}, F1: {f1[0]:.4f}\")\n",
    "print(f\"Positive (Class 1) - Precision: {precision[1]:.4f}, Recall: {recall[1]:.4f}, F1: {f1[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
